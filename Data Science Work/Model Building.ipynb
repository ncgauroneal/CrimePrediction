{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "tune = pd.read_csv('tune.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    250616\n",
       "True     101965\n",
       "Name: arrest, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.arrest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    38235\n",
       "True      9245\n",
       "Name: arrest, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.arrest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_key', 'case_number', 'date', 'block', 'iucr', 'primary_type',\n",
       "       'description', 'location_description', 'arrest', 'domestic', 'beat',\n",
       "       'district', 'ward', 'community_area', 'fbi_code', 'x_coordinate',\n",
       "       'y_coordinate', 'year', 'updated_on', 'latitude', 'longitude',\n",
       "       'location', 'DateTime', 'time', 'day', 'month', 'season',\n",
       "       'crimes_per_year', 'prev_crimes_per_year', 'primary_type_grouped'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.326890756302521"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.389/1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train['arrest']\n",
    "train = train[['year', 'domestic','district','season','month','location_description','description','primary_type_grouped','crimes_per_year']]\n",
    "\n",
    "tune_labels = tune['arrest']\n",
    "tune = tune[['year', 'domestic','district','season','month','location_description','description','primary_type_grouped','crimes_per_year']]\n",
    "\n",
    "test_labels = test['arrest']\n",
    "test = test[['year', 'domestic','district','season','month','location_description','description','primary_type_grouped','crimes_per_year']]\n",
    "\n",
    "#data_model = pd.get_dummies(data_model)\n",
    "#data_model = pd.get_dummies(data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.ward = pd.factorize(train.ward)[0]\n",
    "train.district = pd.factorize(train.district)[0]\n",
    "#train.beat = pd.factorize(train.beat)[0]\n",
    "#train.community_area = pd.factorize(train.community_area)[0]\n",
    "train.location_description = pd.factorize(train.location_description)[0]\n",
    "train.description = pd.factorize(train.description)[0]\n",
    "\n",
    "#tune.ward = pd.factorize(tune.ward)[0]\n",
    "tune.district = pd.factorize(tune.district)[0]\n",
    "#tune.beat = pd.factorize(tune.beat)[0]\n",
    "#tune.community_area = pd.factorize(tune.community_area)[0]\n",
    "tune.location_description = pd.factorize(tune.location_description)[0]\n",
    "tune.description = pd.factorize(tune.description)[0]\n",
    "\n",
    "#test.ward = pd.factorize(test.ward)[0]\n",
    "test.district = pd.factorize(test.district)[0]\n",
    "#test.beat = pd.factorize(test.beat)[0]\n",
    "#test.community_area = pd.factorize(test.community_area)[0]\n",
    "test.location_description = pd.factorize(test.location_description)[0]\n",
    "test.description = pd.factorize(test.description)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.primary_type_grouped = pd.factorize(train.primary_type_grouped)[0]\n",
    "tune.primary_type_grouped = pd.factorize(tune.primary_type_grouped)[0]\n",
    "test.primary_type_grouped = pd.factorize(test.primary_type_grouped)[0]\n",
    "\n",
    "train.season = pd.factorize(train.season)[0]\n",
    "tune.season = pd.factorize(tune.season)[0]\n",
    "test.season = pd.factorize(test.season)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    250616\n",
       "True     101965\n",
       "Name: arrest, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    71495\n",
       "True     23695\n",
       "Name: arrest, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    38235\n",
       "True      9245\n",
       "Name: arrest, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352581, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95190, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47480, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = pd.get_dummies(tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352581, 19)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95190, 19)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47480, 19)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i/10 for i in list(range(1,31))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1,\n",
       " 0.2,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.8,\n",
       " 0.9,\n",
       " 1.0,\n",
       " 1.1,\n",
       " 1.2,\n",
       " 1.3,\n",
       " 1.4,\n",
       " 1.5,\n",
       " 1.6,\n",
       " 1.7,\n",
       " 1.8,\n",
       " 1.9,\n",
       " 2.0,\n",
       " 2.1,\n",
       " 2.2,\n",
       " 2.3,\n",
       " 2.4,\n",
       " 2.5,\n",
       " 2.6,\n",
       " 2.7,\n",
       " 2.8,\n",
       " 2.9,\n",
       " 3.0]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "best_score = f1_score(tune_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ''\n",
    "for column in train.columns:\n",
    "    x = train.drop(column, axis=1)\n",
    "    x_tune = tune.drop(column, axis=1)\n",
    "    model = LogisticRegression(class_weight='balanced').fit(x, train_labels)\n",
    "    y_pred = model.predict(x_tune)\n",
    "    score = f1_score(tune_labels, y_pred)\n",
    "    if score > best_score:\n",
    "        remove_feature = feature\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "best_score = f1_score(tune_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ''\n",
    "for column in train.columns:\n",
    "    x = train.drop(column, axis=1)\n",
    "    x_tune = tune.drop(column, axis=1)\n",
    "    model = DecisionTreeClassifier(class_weight='balanced').fit(x, train_labels)\n",
    "    y_pred = model.predict(x_tune)\n",
    "    score = f1_score(tune_labels, y_pred)\n",
    "    if score > best_score:\n",
    "        remove_feature = feature\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "best_score = f1_score(tune_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ''\n",
    "for column in train.columns:\n",
    "    x = train.drop(column, axis=1)\n",
    "    x_tune = tune.drop(column, axis=1)\n",
    "    model = RandomForestClassifier(class_weight='balanced').fit(x, train_labels)\n",
    "    y_pred = model.predict(x_tune)\n",
    "    score = f1_score(tune_labels, y_pred)\n",
    "    if score > best_score:\n",
    "        remove_feature = feature\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "best_param = 1\n",
    "for C in x:\n",
    "    model = LogisticRegression(C=C,class_weight='balanced').fit(train, train_labels)\n",
    "    y_pred = model.predict(tune)\n",
    "    if f1_score(tune_labels, y_pred) > best_score:\n",
    "        best_param = C\n",
    "        best_score = f1_score(tune_labels, y_pred)\n",
    "print(f\"Best F1 score: {best_score} Best Param: {best_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.78      0.82     71495\n",
      "        True       0.49      0.63      0.55     23695\n",
      "\n",
      "    accuracy                           0.74     95190\n",
      "   macro avg       0.68      0.71      0.69     95190\n",
      "weighted avg       0.77      0.74      0.75     95190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=2.0,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "print(classification_report(tune_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.82      0.84    250616\n",
      "        True       0.60      0.68      0.64    101965\n",
      "\n",
      "    accuracy                           0.78    352581\n",
      "   macro avg       0.73      0.75      0.74    352581\n",
      "weighted avg       0.79      0.78      0.78    352581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=2.0,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(train)\n",
    "print(classification_report(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.73      0.81     38235\n",
      "        True       0.37      0.65      0.47      9245\n",
      "\n",
      "    accuracy                           0.72     47480\n",
      "   macro avg       0.63      0.69      0.64     47480\n",
      "weighted avg       0.79      0.72      0.74     47480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=2.0,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(test)\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=2, max_features=2,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "print(classification_report(tune_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [2,3,4,5]\n",
    "max_features = [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depths: [2, 3, 4, 5]\n",
      "Max Features: [2, 3, 4]\n",
      "Model Number: 0\n",
      "Model Score: 0.37972579975072707 Max Depth: 2 Max Feature: 2\n",
      "Model Number: 1\n",
      "Model Score: 0.5254513579183712 Max Depth: 3 Max Feature: 2\n",
      "Model Number: 2\n",
      "Model Score: 0.43299618922093924 Max Depth: 4 Max Feature: 2\n",
      "Model Number: 3\n",
      "Model Score: 0.4317862165963432 Max Depth: 5 Max Feature: 2\n",
      "Model Number: 4\n",
      "Model Score: 0.4980329481190066 Max Depth: 2 Max Feature: 3\n",
      "Model Number: 5\n",
      "Model Score: 0.3814641547603996 Max Depth: 3 Max Feature: 3\n",
      "Model Number: 6\n",
      "Model Score: 0.4929896482656633 Max Depth: 4 Max Feature: 3\n",
      "Model Number: 7\n",
      "Model Score: 0.535619997921214 Max Depth: 5 Max Feature: 3\n",
      "Model Number: 8\n",
      "Model Score: 0.4150402469952586 Max Depth: 2 Max Feature: 4\n",
      "Model Number: 9\n",
      "Model Score: 0.4329198930994312 Max Depth: 3 Max Feature: 4\n",
      "Model Number: 10\n",
      "Model Score: 0.4606666464100149 Max Depth: 4 Max Feature: 4\n",
      "Model Number: 11\n",
      "Model Score: 0.47612312932042206 Max Depth: 5 Max Feature: 4\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_params = dict()\n",
    "best_params_list = list()\n",
    "index = 0\n",
    "best_index = 0\n",
    "#max_depths = list()\n",
    "max_depths = [2,3,4,5]\n",
    "max_features = [2,3,4]\n",
    "print(f\"Max Depths: {max_depths}\")\n",
    "print(f\"Max Features: {max_features}\")\n",
    "\n",
    "for x in max_features:\n",
    "    #print(x)\n",
    "    for y in max_depths:\n",
    "        print(f\"Model Number: {index}\")\n",
    "        #print('depth')\n",
    "        model = DecisionTreeClassifier(max_features=x,max_depth=y,class_weight='balanced').fit(train, train_labels)\n",
    "        #print('Training Model')\n",
    "        y_pred = model.predict(tune)\n",
    "        score = f1_score(tune_labels, y_pred)\n",
    "        print(f\"Model Score: {score} Max Depth: {y} Max Feature: {x}\")\n",
    "        if score > best_score:\n",
    "            best_score = f1_score(tune_labels, y_pred)\n",
    "            best_index = index\n",
    "        aa = dict()\n",
    "        aa['max_depth'] = y\n",
    "        aa['max_features'] = x\n",
    "        best_params_list.append(aa)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_features': 3}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = best_params_list[best_index]\n",
    "best_params\n",
    "#print(f\"Best F1 score: {best_score} Best Depth: {best_param['max_depth']} Best Features: {best_params['max_features']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535619997921214"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.80      0.83    250616\n",
      "        True       0.58      0.71      0.64    101965\n",
      "\n",
      "    accuracy                           0.77    352581\n",
      "   macro avg       0.73      0.75      0.74    352581\n",
      "weighted avg       0.79      0.77      0.78    352581\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5, max_features=3,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(train)\n",
    "print(classification_report(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.82      0.81     71495\n",
      "        True       0.43      0.41      0.42     23695\n",
      "\n",
      "    accuracy                           0.72     95190\n",
      "   macro avg       0.62      0.61      0.62     95190\n",
      "weighted avg       0.71      0.72      0.72     95190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5, max_features=3,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "print(classification_report(tune_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.88      0.88     38235\n",
      "        True       0.50      0.48      0.49      9245\n",
      "\n",
      "    accuracy                           0.81     47480\n",
      "   macro avg       0.69      0.68      0.69     47480\n",
      "weighted avg       0.80      0.81      0.80     47480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5, max_features=4,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(test)\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'arrest'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-c904ec9bbbb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'arrest'"
     ]
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=2, max_features=2,class_weight='balanced').fit(train, train_labels)\n",
    "y_pred = model.predict(test)\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier().fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "print(classification_report(tune_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier().fit(train, train_labels)\n",
    "y_pred = model.predict(tune)\n",
    "print(classification_report(tune_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1-score is 0.4 for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(tune_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp  = confusion_matrix(tune_labels, y_pred).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    ">>> clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model['district'] = data_model['district'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_model['district']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.drop('district', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_model, y, test_size=0.30, random_state=42)\n",
    "X_tune, X_test, y_tune, y_test = train_test_split(X_test, y_test, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model = model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy: {model.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_model['district']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.drop('district',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(y_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tune.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputClassifier(LogisticRegression()).fit(X_tune, y_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {sc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
